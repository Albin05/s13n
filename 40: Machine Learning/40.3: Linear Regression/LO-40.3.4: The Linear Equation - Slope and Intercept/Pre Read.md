# The Linear Equation - Slope and Intercept

## Concept
The heart of Linear Regression is the equation of a straight line. While algebra classes use $y = mx + c$, in Machine Learning we typically use the notation:

$$y = \theta_0 + \theta_1 x$$

* **$y$ (Target):** The value we want to predict.
* **$x$ (Feature):** The input value.
* **$\theta_1$ (Slope/Weight):** Controls the **steepness** and **direction**. It tells us how much $y$ changes for a 1-unit change in $x$.
* **$\theta_0$ (Intercept/Bias):** Controls the **starting point**. It is the value of $y$ when $x$ is 0.

## Real-World Analogy: The Phone Plan
Imagine a mobile plan costs $5 per month plus $0.10 per minute called.
* **Equation:** $Cost = 5 + (0.10 \times Minutes)$
* **Intercept ($\theta_0 = 5$):** Even if you talk for 0 minutes, you pay $5. This is the baseline bias.
* **Slope ($\theta_1 = 0.10$):** For every extra minute you talk, the cost goes up by $0.10. This is the weight of usage.

## Visualization


## External Resources
* [Article: Slope and Intercept in ML](https://example.com/slope-intercept-ml)
* [Video: Visualizing Linear Equations](https://example.com/visualize-linear-video)
